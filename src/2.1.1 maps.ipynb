{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map plots to create Figure 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: needs to be run with an environment that has cartopy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from cartopy import crs as ccrs, feature as cfeature\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import re\n",
    "import xarray as xr\n",
    "from cmcrameri import cm\n",
    "from matplotlib.colors import to_hex\n",
    "import seaborn as sns\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "#  Suppress warnings issued by Cartopy when downloading data files\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TYPE = \"MeteoSuisse\"\n",
    "\n",
    "KFOLD = True\n",
    "if KFOLD:\n",
    "    NUM_FOLDS = 5\n",
    "    FOLD = 'kfold'\n",
    "else:\n",
    "    NUM_FOLDS = 1\n",
    "    FOLD = 'single_fold'\n",
    "    # --------------------------------------------------\n",
    "# PATHS:\n",
    "# Path to point mass balance\n",
    "path_index_raw = '../../data/MB_modeling/GLAMOS/index/dat_files/'\n",
    "mb_path = \"../../data/MB_modeling/GLAMOS/index/csv_files/massbalance/\"\n",
    "path_latloncoord = mb_path + \"WGSlatloncoord/\"  # lat-lon coord\n",
    "path_GLAMOS_csv = mb_path + \"raw_csv/\"  # raw glamos data\n",
    "path_glacattr = mb_path + \"glacierattr/\"  # lat-lon coord + gl attributes from oggm\n",
    "\n",
    "# Path to ERA5-land\n",
    "path_ERA5 = \"../../data/MB_modeling/ERA5/\"\n",
    "path_era5_stakes = (path_ERA5 + \"ERA5Land-stakes/\"\n",
    "                    )  # path to era land at stakes coordinates\n",
    "path_glogem = \"../../data/GloGEM/dataframes/\"\n",
    "path_ERA5_Land = path_ERA5 + \"ERA5-Land/\"  # whole ERA5-land\n",
    "path_ERA5_Land_hourly = path_ERA5 + \"/ERA5-Land-hourly/ncfiles/\"\n",
    "path_GLAMOS = '../../data/MB_modeling/GLAMOS/'\n",
    "\n",
    "# Path XGBoost and PDD model\n",
    "path_pickles = \"../../data/MB_modeling/PDD/\"\n",
    "path_save_xgboost = \"../../data/MB_modeling/XGBoost/\"\n",
    "path_save_xgboost_stakes = \"../../data/MB_modeling/XGBoost/ind_stakes/\"\n",
    "\n",
    "# Path linear model\n",
    "path_save_LM = \"../../data/MB_modeling/LinearModel/\"\n",
    "path_save_LM_stakes = \"../../data/MB_modeling/LinearModel/ind_stakes/\"\n",
    "\n",
    "# Path meteo suisse:\n",
    "path_MS = '../../data/MB_modeling/MeteoSuisse/stakes/'\n",
    "path_meteogrid = '../../data/MB_modeling/MeteoSuisse/'\n",
    "path_prec = path_meteogrid + 'RhiresM_verified/lonlat/'\n",
    "path_temp = path_meteogrid + '/TabsM_verified/lonlat/'\n",
    "\n",
    "# columns of interest in glamos data:\n",
    "COI = [\n",
    "    \"glims_id\",\n",
    "    \"sgi_id\",\n",
    "    \"rgi_id\",\n",
    "    \"glims_id\",\n",
    "    \"vaw_id\",\n",
    "    \"date_fix0\",\n",
    "    \"date_fix1\",\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "    \"height\",\n",
    "    \"b_a_fix\",\n",
    "    \"b_w_fix\",\n",
    "    \"aspect\",\n",
    "    \"slope\",\n",
    "    \"dis_from_border\",\n",
    "    \"min_el_gl\",\n",
    "    \"max_el_gl\",\n",
    "    \"med_el_gl\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets all stakes and the number of stakes per glacier\n",
    "def get_StakesNum(path_GLAMOS_csv):\n",
    "    onlyfiles = [\n",
    "        f for f in listdir(path_GLAMOS_csv) if isfile(join(path_GLAMOS_csv, f))\n",
    "    ]\n",
    "    glStakesNum, glStakes = {}, {\n",
    "    }  # number of stakes per glacier and stakes names\n",
    "    for f in onlyfiles:\n",
    "        gl = f.split(\"_\")[0]\n",
    "        if gl not in glStakesNum.keys():\n",
    "            glStakesNum[gl] = 1\n",
    "            glStakes[gl] = [f]\n",
    "        else:\n",
    "            glStakesNum[gl] = glStakesNum[gl] + 1\n",
    "            glStakes[gl].append(f)\n",
    "    return glStakesNum, glStakes\n",
    "\n",
    "\n",
    "def get_cmap_hex(cmap, length):\n",
    "    \"\"\"\n",
    "    Function to get a get a list of colours as hex codes\n",
    "\n",
    "    :param cmap:    name of colourmap\n",
    "    :type cmap:     str\n",
    "\n",
    "    :return:        list of hex codes\n",
    "    :rtype:         list\n",
    "    \"\"\"\n",
    "    # Get cmap\n",
    "    rgb = plt.get_cmap(cmap)(np.linspace(0, 1, length))\n",
    "\n",
    "    # Convert to hex\n",
    "    hex_codes = [to_hex(rgb[i, :]) for i in range(rgb.shape[0])]\n",
    "\n",
    "    return hex_codes\n",
    "\n",
    "\n",
    "# Get stakes with at least N years of data\n",
    "def getStakesNyears(glaciers,\n",
    "                    glStakes,\n",
    "                    path_glacattr,\n",
    "                    path_era5_stakes,\n",
    "                    input_type,\n",
    "                    N=20):\n",
    "    glStakes_Nyears, glStakesNum_Nyears = {}, {}\n",
    "    for gl in glaciers:\n",
    "        # One glacier:\n",
    "        for stake in glStakes[gl]:\n",
    "            # Get coordinates and time of file for this stake:\n",
    "            df_stake = read_stake_csv(path_glacattr, stake)\n",
    "\n",
    "            # Read corresponding era 5 values for this stake:\n",
    "            stakeName = re.split(\".csv\", stake)[0][:-3]\n",
    "\n",
    "            if input_type == \"ERA5-Land\":\n",
    "                # Read corresponding era 5 land values for this stake:\n",
    "                xr_temppr = xr.open_dataset(path_era5_stakes +\n",
    "                                            f\"{stakeName}_mb_full.nc\").sortby(\n",
    "                                                \"time\")\n",
    "\n",
    "            if input_type == \"MeteoSuisse\":\n",
    "                # Read corresponding meteo suisse values for this stake:\n",
    "                xr_temppr = xr.open_dataset(\n",
    "                    path_MS + f\"{stakeName}_mb_full.nc\").sortby(\"time\")\n",
    "\n",
    "            begin_xr = pd.to_datetime(xr_temppr[\"time\"].values[0]).year\n",
    "            end_xr = pd.to_datetime(xr_temppr[\"time\"].values[-1]).year\n",
    "\n",
    "            # MB data:\n",
    "            # Check for missing data:\n",
    "            checkMissingYears(df_stake)\n",
    "\n",
    "            # Cut MB data to same years as xr era 5:\n",
    "            df_stake_cut = cutStake(df_stake, begin_xr, end_xr)\n",
    "\n",
    "            # Remove cat 0\n",
    "            target_DF = df_stake_cut[df_stake_cut.vaw_id > 0]\n",
    "\n",
    "            # Keep at least N years:\n",
    "            if len(target_DF) >= N:\n",
    "                # print(stake, len(target_DF))\n",
    "                glStakes_Nyears = updateDic(glStakes_Nyears, gl, stake)\n",
    "\n",
    "    for gl in glStakes_Nyears.keys():\n",
    "        glStakesNum_Nyears[gl] = len(glStakes_Nyears[gl])\n",
    "\n",
    "    glStakes_Nyears_sorted = sorted(glStakesNum_Nyears.items(),\n",
    "                                    key=lambda x: x[1])\n",
    "    return glStakes_Nyears, glStakes_Nyears_sorted\n",
    "\n",
    "\n",
    "# Reads the dataframe of a stake for one glacier\n",
    "def read_stake_csv(path, fileName, coi=COI):\n",
    "    dfStake = pd.read_csv(path + fileName,\n",
    "                          sep=\",\",\n",
    "                          parse_dates=[\"date_fix0\", \"date_fix1\"],\n",
    "                          header=0).drop([\"Unnamed: 0\"], axis=1)\n",
    "    # removes dupl years\n",
    "    dfStake = dfStake.drop_duplicates()\n",
    "    dfStake = remove_dupl_years(dfStake).sort_values(by=\"date_fix0\")\n",
    "    # select only columns of interest\n",
    "    dfStake = dfStake[coi]\n",
    "    return dfStake\n",
    "\n",
    "\n",
    "# Checks for duplicate years for a stake\n",
    "def remove_dupl_years(df_stake):\n",
    "    all_years = []\n",
    "    rows = []\n",
    "    for row_nb in range(len(df_stake)):\n",
    "        year = df_stake.date_fix0.iloc[row_nb].year\n",
    "        if year not in all_years:\n",
    "            all_years.append(year)\n",
    "            rows.append(row_nb)\n",
    "    return df_stake.iloc[rows]\n",
    "\n",
    "\n",
    "# Checks if there is data missing for a stake\n",
    "def checkMissingYears(df_stake):\n",
    "    years_stake = []\n",
    "    for date in df_stake.date_fix0:\n",
    "        years_stake.append(date.year)\n",
    "\n",
    "    missing_years = Diff(\n",
    "        years_stake,\n",
    "        [j for j in range(years_stake[0], years_stake[-1] + 1, 1)])\n",
    "    if len(missing_years) > 0:\n",
    "        print(\"Missing years:\", missing_years)\n",
    "\n",
    "\n",
    "# difference between two lists\n",
    "def Diff(li1, li2):\n",
    "    li_dif = [i for i in li1 + li2 if i not in li1 or i not in li2]\n",
    "    return li_dif\n",
    "\n",
    "\n",
    "# Cuts the dataframe of a stake so that it's the same\n",
    "# time period as ERA5 data\n",
    "def cutStake(df_stake, begin_xr, end_xr):\n",
    "    start_year = df_stake.date_fix0.iloc[0].year\n",
    "    end_year = df_stake.date_fix1.iloc[-1].year\n",
    "    \n",
    "    # print(start_year, end_year, begin_xr, end_xr)\n",
    "\n",
    "    offset_begin = abs(begin_xr - start_year)\n",
    "    offset_end = abs(end_xr - end_year)\n",
    "\n",
    "    df_stake = df_stake.iloc[offset_begin:len(df_stake) - offset_end]\n",
    "    return df_stake\n",
    "\n",
    "\n",
    "# Updates a dictionnary at key with value\n",
    "def updateDic(dic, key, value):\n",
    "    if key not in dic.keys():\n",
    "        dic[key] = [value]\n",
    "    else:\n",
    "        dic[key].append(value)\n",
    "\n",
    "    return dic\n",
    "\n",
    "\n",
    "# Creates a Dataframe to plot a heatmap for variable var over all stakes\n",
    "def createHeatMatrixStakes(path_glacattr, glStakes, coi, var=\"b_a_fix\"):\n",
    "    glaciers = list(glStakes.keys())\n",
    "    s_end, gl_mb, height = {}, {}, {}\n",
    "    start_years, end_years = [], []\n",
    "\n",
    "    # Get values for Heatmap for all stakes\n",
    "    for g in range(len(glaciers)):\n",
    "        gl = glaciers[g]  # One glacier\n",
    "        for stake in glStakes[gl]:\n",
    "            # Get coordinates and time of file for this stake:\n",
    "            fileName = re.split(\".csv\", stake)[0][:-3]\n",
    "            df_stake = read_stake_csv(path_glacattr, stake,\n",
    "                                      coi).sort_values(by=\"date_fix0\")\n",
    "\n",
    "            # remove category 0\n",
    "            df_stake = df_stake[df_stake.vaw_id > 0]\n",
    "\n",
    "            # years:\n",
    "            years = [\n",
    "                df_stake.date_fix0.iloc[i].year\n",
    "                for i in range(len(df_stake.date_fix0))\n",
    "            ]\n",
    "\n",
    "            start_years.append(years[0])\n",
    "            end_years.append(years[-1])\n",
    "\n",
    "            s_end[fileName] = years  # start and end years\n",
    "            gl_mb[fileName] = df_stake[var].values  # MB of stake\n",
    "            height[fileName] = df_stake.height.iloc[0]  # Height of stake\n",
    "\n",
    "    # Sort stakes per elevation\n",
    "    stakes_per_el = pd.Series(height).sort_values(ascending=False).index\n",
    "\n",
    "    # Create DF with MB for each year for all stakes\n",
    "    totalDF = pd.DataFrame(\n",
    "        data={\n",
    "            \"years\": range(np.min(start_years),\n",
    "                           np.max(end_years) +\n",
    "                           1),  # total years over all stakes\n",
    "            \"pres\": np.ones((np.max(end_years) + 1) -\n",
    "                            np.min(start_years)),  # unimportant column\n",
    "        })\n",
    "\n",
    "    for stake in stakes_per_el:\n",
    "        fileName = re.split(\".csv\", stake)[0]\n",
    "        start_year, end_year = s_end[fileName][0], s_end[fileName][-1]\n",
    "        year_gl = pd.DataFrame(\n",
    "            data={\n",
    "                \"years\":\n",
    "                s_end[fileName],  # Years where stake has been measured\n",
    "                fileName: gl_mb[fileName],  # MB for that stake\n",
    "            })\n",
    "        totalDF = pd.merge(totalDF, year_gl, on=\"years\",\n",
    "                           how=\"left\")  # Add that stake to DF\n",
    "    totalDF = totalDF.set_index(\"years\").drop([\"pres\"], axis=1)\n",
    "    return totalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of stakes per glacier and their names\n",
    "glStakesNum, glStakes = get_StakesNum(path_GLAMOS_csv)\n",
    "glStakes_sorted = sorted(glStakesNum.items(), key=lambda x: x[1])\n",
    "\n",
    "# Get total number of stakes\n",
    "num_stakes = 0\n",
    "for (glacier, num) in (glStakes_sorted):\n",
    "    num_stakes += num\n",
    "print('Total number of stakes:', num_stakes)\n",
    "print('Number of stakes per glacier:\\n', glStakes_sorted)\n",
    "\n",
    "# glacier names:\n",
    "glaciers = list(glStakes.keys())\n",
    "# Keep only the glaciers with more than 20 years of measurements\n",
    "glStakes_20years, glStakes_20years_sorted = getStakesNyears(\n",
    "    glaciers,\n",
    "    glStakes,\n",
    "    path_glacattr,\n",
    "    path_era5_stakes,\n",
    "    input_type=INPUT_TYPE,\n",
    "    N=20)\n",
    "print('After preprocessing:\\n----\\nNumber of glaciers:',\n",
    "      len(glStakes_20years.keys()))\n",
    "num_stakes = 0\n",
    "for gl in glStakes_20years.keys():\n",
    "    num_stakes += len(glStakes_20years[gl])\n",
    "print('Number of stakes:', num_stakes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stakes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_stakes = {}\n",
    "for gl in glStakes_20years:\n",
    "    # One glacier:\n",
    "    for stake in glStakes_20years[gl]:\n",
    "        # Get coordinates and time of file for this stake:\n",
    "        df_stake = read_stake_csv(path_glacattr, stake)\n",
    "\n",
    "        # Read corresponding era 5 values for this stake:\n",
    "        stakeName = re.split(\".csv\", stake)[0][:-3]\n",
    "\n",
    "        if INPUT_TYPE == \"ERA5-Land\":\n",
    "            # Read corresponding era 5 land values for this stake:\n",
    "            xr_temppr = xr.open_dataset(\n",
    "                path_era5_stakes + f\"{stakeName}_mb_full.nc\").sortby(\"time\")\n",
    "\n",
    "        if INPUT_TYPE == \"MeteoSuisse\":\n",
    "            # Read corresponding meteo suisse values for this stake:\n",
    "            xr_temppr = xr.open_dataset(\n",
    "                path_MS + f\"{stakeName}_mb_full.nc\").sortby(\"time\")\n",
    "\n",
    "        begin_xr = pd.to_datetime(xr_temppr[\"time\"].values[0]).year\n",
    "        end_xr = pd.to_datetime(xr_temppr[\"time\"].values[-1]).year\n",
    "        \n",
    "        # print(stakeName, begin_xr, end_xr)\n",
    "\n",
    "        # MB data:\n",
    "        # Check for missing data:\n",
    "        checkMissingYears(df_stake)\n",
    "\n",
    "        # Cut MB data to same years as xr era 5:\n",
    "        df_stake_cut = cutStake(df_stake, begin_xr, end_xr)\n",
    "        # print(df_stake_cut)\n",
    "\n",
    "        # Remove cat 0\n",
    "        target_DF = df_stake_cut[df_stake_cut.vaw_id > 0]\n",
    "\n",
    "        # Keep at least N years:\n",
    "        len_stakes[stakeName] = len(target_DF)\n",
    "\n",
    "stakes_info = pd.DataFrame({\n",
    "    'stakes': len_stakes.keys(),\n",
    "    'Numb. meas.': len_stakes.values()\n",
    "})\n",
    "lats, lons = [], []\n",
    "for stake in stakes_info.stakes:\n",
    "    df_stake = read_stake_csv(path_glacattr, f'{stake}_mb.csv')\n",
    "    stake_lat, stake_lon = df_stake.lat.mean(), df_stake.lon.mean()\n",
    "    lats.append(stake_lat)\n",
    "    lons.append(stake_lon)\n",
    "\n",
    "stakes_info['lat'] = lats\n",
    "stakes_info['lon'] = lons\n",
    "\n",
    "glacier_correct = {'aletsch':'Aletsch', 'allalin':'Allalin', 'basodino':'Basodino', 'clariden':'Clariden', 'corbassiere':'Corbassiere',\n",
    "       'gietro':'Gietro', 'gries':'Gries', 'hohlaub':'Hohlaub', 'limmern':'Limmern', 'pers':'Pers', 'plattalva':'Plattalva',\n",
    "       'schwarzberg':'Schwarzberg', 'silvretta':'Silvretta'}\n",
    "stakes_info['Glacier'] = [glacier_correct[stake.split('_')[0]] for stake in stakes_info.stakes]\n",
    "stakes_info.sort_values(by='Glacier', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stakes_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure object\n",
    "fig = plt.figure(\n",
    "    figsize=(15, 10)\n",
    ")  # Notice we need a bigger \"canvas\" so these two maps will be of a decent size\n",
    "\n",
    "# Set the domain for defining the second plot region.\n",
    "latN = 48\n",
    "latS = 45.8\n",
    "lonW = 5.8\n",
    "lonE = 10.5\n",
    "cLat = (latN + latS) / 2\n",
    "cLon = (lonW + lonE) / 2\n",
    "\n",
    "\n",
    "# Add background image:\n",
    "class StadiaStamen(cimgt.Stamen):\n",
    "    def _image_url(self, tile):\n",
    "        x, y, z = tile\n",
    "        API_KEY = \"000378bd-b0f0-46e2-a46d-f2165b0c6c02\"\n",
    "        url = f\"https://tiles.stadiamaps.com/tiles/stamen_terrain_background/{z}/{x}/{y}.png?api_key={API_KEY}\"\n",
    "        # url = f\"https://tiles.stadiamaps.com/tiles/stamen_terrain/{z}/{x}/{y}.png?api_key={API_KEY}\"\n",
    "        return url\n",
    "\n",
    "\n",
    "stamen_terrain = StadiaStamen(\"terrain-background\")\n",
    "projPC = ccrs.PlateCarree()\n",
    "\n",
    "# Create a Geoax2es in the tile's projection.\n",
    "ax2 = plt.axes(projection=stamen_terrain.crs)\n",
    "\n",
    "# Limit the extent of the map to a small longitude/latitude range.\n",
    "ax2.set_extent([lonW, lonE, latS, latN], crs=ccrs.Geodetic())\n",
    "\n",
    "# Add the Stamen data at zoom level 8.\n",
    "ax2.add_image(stamen_terrain, 8, alpha=0.7)\n",
    "ax2.add_feature(cfeature.COASTLINE)\n",
    "ax2.add_feature(cfeature.BORDERS, linestyle='-', linewidth=1)\n",
    "\n",
    "# cmap = cm.acton\n",
    "# cmap = sns.color_palette(\"colorblind\")\n",
    "# color_palette_glaciers = sns.color_palette(\n",
    "#     get_cmap_hex(cmap, 20))\n",
    "color_palette_glaciers = sns.color_palette(\"colorblind\")\n",
    "\n",
    "g = sns.scatterplot(stakes_info,\n",
    "                    x='lon',\n",
    "                    y='lat',\n",
    "                    size=\"Numb. meas.\",\n",
    "                    hue=\"Glacier\",\n",
    "                    sizes=(200, 1500),\n",
    "                    alpha=.6,\n",
    "                    palette=color_palette_glaciers,\n",
    "                    transform=projPC,\n",
    "                    ax=ax2,\n",
    "                    zorder = 10)\n",
    "h, l = g.get_legend_handles_labels()\n",
    "\n",
    "# Pick only important information\n",
    "# h_sub, l_sub = [h[14]]+h[15:18]+[h[19]], [l[14]]+l[15:18]+[l[19]]\n",
    "h_sub, l_sub = h[15:18]+[h[19]], l[15:18]+[l[19]]\n",
    "l_sub = ['21', '30', '40', '62']\n",
    "\n",
    "ax2.legend(h_sub,\n",
    "           l_sub,\n",
    "           bbox_to_anchor=(1.05, 1),\n",
    "           loc=2,\n",
    "        #    ncol=2,\n",
    "           borderaxespad=0.5,\n",
    "           frameon=False,\n",
    "           fontsize=16,\n",
    "           markerscale=1,\n",
    "           title = 'Numb. meas.',\n",
    "           title_fontsize = 16)\n",
    "\n",
    "\n",
    "# kw = dict(prop=\"sizes\", num=5, color=scatter.cmap(0.7), fmt=\"$ {x:.2f}\",\n",
    "#           func=lambda s: np.sqrt(s/.3)/3)\n",
    "# legend2 = ax.legend(*scatter.legend_elements(**kw),\n",
    "#                     loc=\"lower right\", title=\"Price\")\n",
    "\n",
    "gl = ax2.gridlines(draw_labels=True,\n",
    "                   linewidth=1,\n",
    "                   color='gray',\n",
    "                   alpha=0.5,\n",
    "                   linestyle='--')\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'size': 16, 'color': 'black'}\n",
    "gl.ylabel_style = {'size': 16, 'color': 'black'}\n",
    "gl.top_labels = gl.right_labels = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glaciers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info_gl = pd.DataFrame(\n",
    "    stakes_info.groupby('Glacier').sum()['Numb. meas.']).reset_index()\n",
    "df_info_gl_loc = pd.DataFrame(\n",
    "    stakes_info[['Glacier', 'lat',\n",
    "                 'lon']].groupby('Glacier').mean()).reset_index()\n",
    "df_info_gl = df_info_gl.merge(df_info_gl_loc, on='Glacier')\n",
    "# df_info_gl['range'] = pd.cut(df_info_gl['num_meas'], [0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the figure object\n",
    "fig = plt.figure(\n",
    "    figsize=(15, 10)\n",
    ")  # Notice we need a bigger \"canvas\" so these two maps will be of a decent size\n",
    "\n",
    "# Set the domain for defining the second plot region.\n",
    "latN = 48\n",
    "latS = 45.8\n",
    "lonW = 5.8\n",
    "lonE = 10.5\n",
    "cLat = (latN + latS) / 2\n",
    "cLon = (lonW + lonE) / 2\n",
    "\n",
    "\n",
    "# Add background image:\n",
    "class StadiaStamen(cimgt.Stamen):\n",
    "    def _image_url(self, tile):\n",
    "        x, y, z = tile\n",
    "        API_KEY = \"000378bd-b0f0-46e2-a46d-f2165b0c6c02\"\n",
    "        url = f\"https://tiles.stadiamaps.com/tiles/stamen_terrain_background/{z}/{x}/{y}.png?api_key={API_KEY}\"\n",
    "        # url = f\"https://tiles.stadiamaps.com/tiles/stamen_terrain/{z}/{x}/{y}.png?api_key={API_KEY}\"\n",
    "        return url\n",
    "\n",
    "\n",
    "stamen_terrain = StadiaStamen(\"terrain-background\")\n",
    "projPC = ccrs.PlateCarree()\n",
    "\n",
    "# Create a Geoax2es in the tile's projection.\n",
    "ax2 = plt.axes(projection=stamen_terrain.crs)\n",
    "\n",
    "# Limit the extent of the map to a small longitude/latitude range.\n",
    "ax2.set_extent([lonW, lonE, latS, latN], crs=ccrs.Geodetic())\n",
    "\n",
    "# Add the Stamen data at zoom level 8.\n",
    "ax2.add_image(stamen_terrain, 8, alpha=0.7)\n",
    "ax2.add_feature(cfeature.COASTLINE)\n",
    "ax2.add_feature(cfeature.BORDERS, linestyle='-', linewidth=1.5)\n",
    "\n",
    "cmap = cm.acton\n",
    "color_palette_glaciers = sns.color_palette(\n",
    "    get_cmap_hex(cmap, 20))\n",
    "# color_palette_glaciers = sns.color_palette(\"deep\")\n",
    "\n",
    "g = sns.scatterplot(df_info_gl,\n",
    "                    x='lon',\n",
    "                    y='lat',\n",
    "                    size=\"Numb. meas.\",\n",
    "                    hue=\"Glacier\",\n",
    "                    sizes=(200, 1500),\n",
    "                    alpha=.8,\n",
    "                    palette=color_palette_glaciers,\n",
    "                    transform=projPC,\n",
    "                    ax=ax2,\n",
    "                    zorder = 10)\n",
    "h, l = g.get_legend_handles_labels()\n",
    "\n",
    "ax2.legend(h,\n",
    "           l,\n",
    "           bbox_to_anchor=(1.05, 1),\n",
    "           loc=2,\n",
    "           ncol=2,\n",
    "           borderaxespad=0.5,\n",
    "           frameon=False,\n",
    "           fontsize=14,\n",
    "           markerscale=1)\n",
    "gl = ax2.gridlines(draw_labels=True,\n",
    "                   linewidth=1,\n",
    "                   color='gray',\n",
    "                   alpha=0.5,\n",
    "                   linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
