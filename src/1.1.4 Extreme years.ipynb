{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom model run on extreme years:\n",
    "\n",
    "This notebook allows running XGBoost++ or other models on custom data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import warnings\n",
    "import re\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV as RSCV\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter, MaxNLocator\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.xgb_helpers import *\n",
    "from scripts.stakes_processing import *\n",
    "from scripts.xgb_input import *\n",
    "from scripts.xgb_model import *\n",
    "from scripts.xgb_model_varcomb import *\n",
    "from scripts.plots_clean import *\n",
    "from scripts.xgb_metrics import *\n",
    "from scripts.xgb_extreme import *\n",
    "from scripts.PDD_model_modules import *\n",
    "from scripts.PDD_model_calibration import *\n",
    "from scripts.PDD_helpers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed everywhere:\n",
    "seed_all(SEED)\n",
    "\n",
    "# Parameter grid of XGBoost training Hyperparameters\n",
    "param_grid = {\n",
    "    'learning_rate': np.arange(0.01, 0.2, 0.01),\n",
    "    'n_estimators': np.arange(50, 300, 15),\n",
    "    'max_depth': np.arange(3, 10, 1),\n",
    "}\n",
    "INPUT_TYPE = \"MeteoSuisse\"\n",
    "\n",
    "KFOLD = True\n",
    "if KFOLD:\n",
    "    NUM_FOLDS = 5\n",
    "    FOLD = 'kfold'\n",
    "else:\n",
    "    NUM_FOLDS = 1\n",
    "    FOLD = 'single_fold'\n",
    "\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot styles:\n",
    "path_style_sheet = 'scripts/example.mplstyle'\n",
    "plt.style.use(path_style_sheet)\n",
    "\n",
    "# Colors:\n",
    "palette_grays = sns.color_palette(np.tile(\"#878787\", 6))\n",
    "cmap = cm.devon\n",
    "color_palette_glaciers = sns.color_palette(get_cmap_hex(cmap, 15))\n",
    "\n",
    "# For bars and lines:\n",
    "color_diff_xgb = '#878787'\n",
    "color_diff_xgbplus = '#4d4d4d'\n",
    "\n",
    "colors = get_cmap_hex(cm.batlow, 2)\n",
    "color_xgbplus = colors[0]\n",
    "# color_tim = colors[1]\n",
    "# color_tim = '#b2182b'\n",
    "color_tim = '#c51b7d'\n",
    "color_xgb = '#4575b4'\n",
    "\n",
    "# Violin and boxplots:\n",
    "colors_temp_freq = sns.color_palette(get_cmap_hex(cm.devon, 8))\n",
    "boxplot_style = {\n",
    "    \"width\": .6,\n",
    "    \"showcaps\": False,\n",
    "    \"palette\": colors_temp_freq,\n",
    "    \"flierprops\": {\n",
    "        \"marker\": \"x\"\n",
    "    },\n",
    "    \"showmeans\": True,\n",
    "    \"meanprops\": {\n",
    "        \"markerfacecolor\": \"white\"\n",
    "    }\n",
    "}\n",
    "\n",
    "marker_tim = 's'\n",
    "marker_xgb = 'o'\n",
    "marker_std = '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of stakes per glacier and their names\n",
    "glStakesNum, glStakes = get_StakesNum(path_GLAMOS_csv)\n",
    "glStakes_sorted = sorted(glStakesNum.items(), key=lambda x: x[1])\n",
    "\n",
    "# Get total number of stakes\n",
    "num_stakes = 0\n",
    "for (glacier, num) in (glStakes_sorted):\n",
    "    num_stakes += num\n",
    "print('Total number of stakes:', num_stakes)\n",
    "print('Number of stakes per glacier:\\n', glStakes_sorted)\n",
    "\n",
    "# glacier names:\n",
    "glaciers = list(glStakes.keys())\n",
    "\n",
    "# Select stakes that have at least 20 years of measurements\n",
    "glStakes_20years, glStakes_20years_sorted, glStakes_20years_all = getStakesNyears(\n",
    "    glaciers,\n",
    "    glStakes,\n",
    "    path_glacattr,\n",
    "    path_era5_stakes,\n",
    "    input_type=INPUT_TYPE,\n",
    "    N=20)\n",
    "print('After preprocessing:\\n----\\nNumber of glaciers:',\n",
    "      len(glStakes_20years.keys()))\n",
    "num_stakes = 0\n",
    "for gl in glStakes_20years.keys():\n",
    "    num_stakes += len(glStakes_20years[gl])\n",
    "print('Number of stakes:', num_stakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename stakes so that ordered by elevation from P1 to P(X highest):\n",
    "glaciers = list(glStakes_20years.keys())\n",
    "s_end, gl_mb, = {}, {}\n",
    "start_years, end_years = [], []\n",
    "stakes_per_el = {}\n",
    "var = \"b_a_fix\"\n",
    "for g in range(len(glaciers)):\n",
    "    gl = glaciers[g]  # One glacier\n",
    "    height = {}\n",
    "    for stake in glStakes_20years[gl]:\n",
    "        # Get coordinates and time of file for this stake:\n",
    "        fileName = re.split(\".csv\", stake)[0][:-3]\n",
    "        df_stake = read_stake_csv(path_glacattr, stake,\n",
    "                                  COI).sort_values(by=\"date_fix0\")\n",
    "\n",
    "        # remove category 0\n",
    "        df_stake = df_stake[df_stake.vaw_id > 0]\n",
    "\n",
    "        # remove 2021:\n",
    "        df_stake = df_stake[df_stake.date_fix0.dt.year < 2021]\n",
    "\n",
    "        # years:\n",
    "        years = [\n",
    "            df_stake.date_fix0.iloc[i].year\n",
    "            for i in range(len(df_stake.date_fix0))\n",
    "        ]\n",
    "\n",
    "        start_years.append(years[0])\n",
    "        end_years.append(years[-1])\n",
    "\n",
    "        s_end[fileName] = years  # start and end years\n",
    "        gl_mb[fileName] = df_stake[var].values / (\n",
    "            1000)  # MB of stake (change to m w.e.)\n",
    "        height[fileName] = df_stake.height.iloc[0]  # Height of stake\n",
    "\n",
    "    # Sort stakes per elevation\n",
    "    print(height)\n",
    "    stakes_per_el[gl] = list(\n",
    "        pd.Series(height).sort_values(ascending=True).index.values)\n",
    "\n",
    "rename_stakes, glStakes_20years_renamed = {}, {}\n",
    "for gl in stakes_per_el.keys():\n",
    "    for i, stake in enumerate(stakes_per_el[gl]):\n",
    "        rename_stakes[stake] = f\"{GLACIER_CORRECT[gl]}-P{i+1}\"\n",
    "        updateDic(glStakes_20years_renamed, gl,\n",
    "                  f\"{GLACIER_CORRECT[gl]}-P{i+1}\")\n",
    "\n",
    "rename_stakes, glStakes_20years_renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalDF_mb, el_stakes = createHeatMatrixStakes(path_glacattr,\n",
    "                                               glStakes_20years,\n",
    "                                               COI,\n",
    "                                               var=\"b_a_fix\")\n",
    "\n",
    "DF60s = totalDF_mb[(totalDF_mb.index > 1961)]\n",
    "totalDF_mb_tr = DF60s.transpose().reset_index()\n",
    "stakes = totalDF_mb_tr['index']\n",
    "gl_correct = [\n",
    "    GLACIER_CORRECT[stake.split('_')[0]] + ' - {}'.format(stake.split('_')[1])\n",
    "    for stake in stakes\n",
    "]\n",
    "totalDF_mb_tr['stakeNames'] = gl_correct\n",
    "totalDF_mb_tr = totalDF_mb_tr.drop(['index'], axis=1).set_index('stakeNames')\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "sns.heatmap(data=totalDF_mb_tr,\n",
    "            center=0,\n",
    "            cmap=cm.vik_r,\n",
    "            cbar_kws={'label': '[m w.e. $a^{-1}$]'},\n",
    "            ax=ax)\n",
    "ax.set_ylabel('')\n",
    "ax.set_xlabel(\"Years\", fontsize=18)\n",
    "plt.savefig(\"figures/fig1_stakesHeatmap.pdf\",\n",
    "            format=\"pdf\",\n",
    "            bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stakesExtreme = [\n",
    "    'aletsch_P3', 'gietro_P1', 'gietro_P5', 'basodino_P8', 'gries_P112',\n",
    "    'hohlaub_P2', 'silvretta_BO', 'clariden_U', 'allalin_P1', 'pers_P24',\n",
    "    'basodino_P5', 'gietro_P3', 'schwarzberg_P2', 'silvretta_BU',\n",
    "    'basodino_P10', 'clariden_L', 'corbassiere_B2', 'gries_P32',\n",
    "    'silvretta_P9', 'aletsch_P0'\n",
    "]\n",
    "\n",
    "glStakesExtreme = {}\n",
    "for stake in stakesExtreme:\n",
    "    glacier = stake.split('_')[0]\n",
    "    updateDic(glStakesExtreme, glacier, f'{stake}_mb.csv')\n",
    "glStakesExtreme, len(stakesExtreme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalDF_mb, el_stakes = createHeatMatrixStakes(path_glacattr,\n",
    "                                               glStakesExtreme,\n",
    "                                               COI,\n",
    "                                               var=\"b_a_fix\")\n",
    "\n",
    "DF60s = totalDF_mb[(totalDF_mb.index > 1961)]\n",
    "totalDF_mb_tr = DF60s.transpose().reset_index()\n",
    "stakes = totalDF_mb_tr['index']\n",
    "# gl_correct = [\n",
    "#     GLACIER_CORRECT[stake.split('_')[0]] + ' - {}'.format(stake.split('_')[1])\n",
    "#     for stake in stakes\n",
    "# ]\n",
    "# totalDF_mb_tr['stakeNames'] = gl_correct\n",
    "totalDF_mb_tr['stakeNames'] = [rename_stakes[stake] for stake in stakes]\n",
    "totalDF_mb_tr = totalDF_mb_tr.drop(['index'], axis=1).set_index('stakeNames')\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "sns.heatmap(data=totalDF_mb_tr,\n",
    "            center=0,\n",
    "            cmap=cm.vik_r,\n",
    "            cbar_kws={'label': '[m w.e. $a^{-1}$]'},\n",
    "            ax=ax)\n",
    "ax.set_ylabel('')\n",
    "ax.set_xlabel(\"Years\", fontsize=18)\n",
    "plt.savefig(\"figures/fig1_stakesHeatmap.pdf\",\n",
    "            format=\"pdf\",\n",
    "            bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run XGB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_combi = [(['t2m_May', 't2m_June', 't2m_July', 't2m_Aug', 't2m_Sep'], [\n",
    "    'tp_Oct',\n",
    "    'tp_Nov',\n",
    "    'tp_Dec',\n",
    "    'tp_Jan',\n",
    "    'tp_Feb',\n",
    "])]\n",
    "\n",
    "\n",
    "if KFold:\n",
    "    fold = \"kfold\"\n",
    "else:\n",
    "    fold = \"single_fold\"\n",
    "\n",
    "path_extreme = path_save_xgboost_stakes + f\"{fold}/{INPUT_TYPE}/extreme_years/\"\n",
    "\n",
    "print(f\"Creating path: {path_extreme}\")\n",
    "# Empty folder and create path if non existance\n",
    "createPath(path_extreme)\n",
    "# emptyfolder(path_extreme)\n",
    "\n",
    "glaciers = list(glStakes_20years.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of different inputs:\n",
    "stake = 'clariden_U_mb.csv'\n",
    "stakeName = stake.split('_')[0] + '_' + stake.split('_')[1]\n",
    "print(f\"Processing {glacier} - {stakeName}\")\n",
    "\n",
    "weights_t2m = np.ones(len(best_combi[0][0]))\n",
    "weights_tp = np.ones(len(best_combi[0][1]))\n",
    "\n",
    "# Create input and target for model:\n",
    "vars_ = ['t2m', 'tp']\n",
    "inputDF, target, xr_full = createSingleInput(best_combi,\n",
    "                                             weights_t2m,\n",
    "                                             weights_tp,\n",
    "                                             stakeName,\n",
    "                                             INPUT_TYPE,\n",
    "                                             vars_,\n",
    "                                             log=False)\n",
    "\n",
    "vars_ = ['t2m_corr', 'tp_corr']\n",
    "inputDF_corr, target_corr, xr_full = createSingleInput(best_combi,\n",
    "                                                       weights_t2m,\n",
    "                                                       weights_tp,\n",
    "                                                       stakeName,\n",
    "                                                       INPUT_TYPE,\n",
    "                                                       vars_,\n",
    "                                                       log=False)\n",
    "\n",
    "vars_ = ['pdd', 'tp_corr']\n",
    "inputDF_pdd, target_pdd, xr_full = createSingleInput(best_combi,\n",
    "                                                     weights_t2m,\n",
    "                                                     weights_tp,\n",
    "                                                     stakeName,\n",
    "                                                     INPUT_TYPE,\n",
    "                                                     vars_,\n",
    "                                                     log=False)\n",
    "\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "ax.plot(inputDF['t2m_mean'], label='MS')\n",
    "ax.plot(inputDF_corr['t2m_mean'], label='MS stake')\n",
    "ax.plot(inputDF_pdd['t2m_mean'], label='MS stake pdd')\n",
    "ax.legend()\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "ax.plot(inputDF['tp_tot'], label='MS')\n",
    "ax.plot(inputDF_corr['tp_tot'], label='MS stake')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tested on 2022 and 2023:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emptyfolder(path_extreme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# test on 2022 and 2023:\n",
    "RUN = False\n",
    "# possible_var = [['t2m', 'tp'], ['t2m_corr', 'tp_corr'], ['pdd', 'tp_corr']]\n",
    "possible_var = [['t2m', 'tp']]\n",
    "\n",
    "weights_t2m = np.ones(len(best_combi[0][0]))\n",
    "weights_tp = np.ones(len(best_combi[0][1]))\n",
    "\n",
    "if RUN:\n",
    "    for varcombi in possible_var:\n",
    "        print('Running for variables:', varcombi)\n",
    "        test_index = [2022, 2023]\n",
    "        pred_stake, metrics_stake, target_stake = [], [], []\n",
    "        std_obs_stake = []\n",
    "        for glacier in tqdm(glStakesExtreme.keys(), desc='glaciers'):\n",
    "            for stake in glStakesExtreme[glacier]:\n",
    "                stakeName = stake.split('_')[0] + '_' + stake.split('_')[1]\n",
    "                # print(f\"Processing {glacier} - {stakeName}\")\n",
    "                # Create input and target for model:\n",
    "                inputDF, target, xr_full = createSingleInput(best_combi,\n",
    "                                                             weights_t2m,\n",
    "                                                             weights_tp,\n",
    "                                                             stakeName,\n",
    "                                                             INPUT_TYPE,\n",
    "                                                             log=False,\n",
    "                                                             vars_=varcombi)\n",
    "\n",
    "                # Separate into training and testing:\n",
    "                X, y, time = createSingleInputArraysExtreme(test_index,\n",
    "                                                            target,\n",
    "                                                            inputDF,\n",
    "                                                            log=False)\n",
    "\n",
    "                # apply XGBoost model:\n",
    "                predictions_XG, val_loss, train_loss, epochs, best_iteration, params_RF = applySingleXGBoost(\n",
    "                    X, y, param_grid, log=False)\n",
    "                rmse, mae, pearson, rsquared2 = evalMetrics(\n",
    "                    y[\"test\"], predictions_XG)\n",
    "                pred_stake.append(predictions_XG)\n",
    "                metrics_stake.append([rmse, mae, np.std(y['train2'])])\n",
    "                target_stake.append(y[\"test\"])\n",
    "\n",
    "        # Assemble for all stakes:\n",
    "        dfMetrics_xgb = pd.DataFrame(metrics_stake,\n",
    "                                     columns=['RMSE', 'MAE', 'std_obs'])\n",
    "        dfMetrics_xgb = dfMetrics_xgb[['RMSE', 'MAE', 'std_obs']] / (1000)\n",
    "\n",
    "        dfMetrics_xgb['stake'] = np.concatenate([[\n",
    "            stake.split('_')[0] + '_' + stake.split('_')[1]\n",
    "            for stake in glStakesExtreme[gl]\n",
    "        ] for gl in glStakesExtreme.keys()])\n",
    "        dfMetrics_xgb['stake'] = dfMetrics_xgb['stake'].apply(\n",
    "            lambda x: rename_stakes[x])\n",
    "        dfMetrics_xgb['glacier'] = np.concatenate(\n",
    "            [[gl] * len(glStakesExtreme[gl]) for gl in glStakesExtreme.keys()])\n",
    "\n",
    "        dfPred_xgb = pd.DataFrame(pred_stake, columns=test_index)\n",
    "        dfPred_xgb[['2022_target', '2023_target']] = target_stake\n",
    "        dfPred_xgb['stake'] = np.concatenate([[\n",
    "            stake.split('_')[0] + '_' + stake.split('_')[1]\n",
    "            for stake in glStakesExtreme[gl]\n",
    "        ] for gl in glStakesExtreme.keys()])\n",
    "        dfPred_xgb['stake'] = dfPred_xgb['stake'].apply(\n",
    "            lambda x: rename_stakes[x])\n",
    "        dfPred_xgb['glacier'] = np.concatenate(\n",
    "            [[gl] * len(glStakesExtreme[gl]) for gl in glStakesExtreme.keys()])\n",
    "\n",
    "        # Metrics on 2022 and 2023 alone:\n",
    "        dfMetrics_xgb['RMSE_2022'] = dfPred_xgb.apply(\n",
    "            lambda x: mean_squared_error([x[2022]], [x['2022_target']],\n",
    "                                         squared=False),\n",
    "            axis=1) / (1000)\n",
    "        dfMetrics_xgb['RMSE_2023'] = dfPred_xgb.apply(\n",
    "            lambda x: mean_squared_error([x[2023]], [x['2023_target']],\n",
    "                                         squared=False),\n",
    "            axis=1) / (1000)\n",
    "        dfMetrics_xgb['MAE_2022'] = dfPred_xgb.apply(\n",
    "            lambda x: mean_absolute_error([x[2022]], [x['2022_target']]),\n",
    "            axis=1) / (1000)\n",
    "        dfMetrics_xgb['MAE_2023'] = dfPred_xgb.apply(\n",
    "            lambda x: mean_absolute_error([x[2023]], [x['2023_target']]),\n",
    "            axis=1) / (1000)\n",
    "\n",
    "        # Save to csv:\n",
    "        name_metrics = f'metrics_2022_2023_{varcombi[0]}_{varcombi[1]}.csv'\n",
    "        print(f'Save {name_metrics} to {path_extreme}')\n",
    "        dfMetrics_xgb.to_csv(path_extreme + name_metrics)\n",
    "        name_pred = f'predictions_2022_2023_{varcombi[0]}_{varcombi[1]}.csv'\n",
    "        print(f'Save {name_pred} to {path_extreme}')\n",
    "        dfPred_xgb.to_csv(path_extreme + name_pred)\n",
    "\n",
    "# Tested on 2022 and 2023:\n",
    "dfMetrics_xgb_2022_2023 = pd.read_csv(path_extreme +\n",
    "                                      'metrics_2022_2023_t2m_tp.csv')\n",
    "dfPred_xgb_2022_2023 = pd.read_csv(path_extreme +\n",
    "                                   'predictions_2022_2023_t2m_tp.csv')\n",
    "dfPred_xgb_2022_2023.rename(columns={'2023': 2023, '2022': 2022}, inplace=True)\n",
    "dfPred_xgb_2022_2023.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tested on 2023:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on 2023 only:\n",
    "RUN = False\n",
    "# possible_var = [['t2m', 'tp'], ['t2m_corr', 'tp_corr'], ['pdd', 'tp_corr']]\n",
    "possible_var = [['t2m', 'tp']]\n",
    "\n",
    "if RUN:\n",
    "    for varcombi in possible_var:\n",
    "        print('Running for variables:', varcombi)\n",
    "        test_index = [2023]\n",
    "        pred_stake, metrics_stake, target_stake = [], [], []\n",
    "        params_stake = []\n",
    "        for glacier in tqdm(glStakesExtreme.keys(), desc='glaciers'):\n",
    "            for stake in glStakesExtreme[glacier]:\n",
    "                stakeName = stake.split('_')[0] + '_' + stake.split('_')[1]\n",
    "                stakeName = 'silvretta_BU'\n",
    "                # Create input and target for model:\n",
    "                inputDF, target, xr_full = createSingleInput(best_combi,\n",
    "                                                             weights_t2m,\n",
    "                                                             weights_tp,\n",
    "                                                             stakeName,\n",
    "                                                             INPUT_TYPE,\n",
    "                                                             log=False,\n",
    "                                                             vars_=varcombi)\n",
    "                print(inputDF.shape)\n",
    "                print(inputDF)\n",
    "\n",
    "                # Separate into training and testing:\n",
    "                X, y, time = createSingleInputArraysExtreme(test_index,\n",
    "                                                            target,\n",
    "                                                            inputDF,\n",
    "                                                            log=False)\n",
    "\n",
    "                # apply XGBoost model:\n",
    "                predictions_XG, val_loss, train_loss, epochs, best_iteration, params_RF = applySingleXGBoost(\n",
    "                    X, y, param_grid, log=False)\n",
    "                rmse, mae, pearson, rsquared2 = evalMetrics(\n",
    "                    y[\"test\"], predictions_XG)\n",
    "                pred_stake.append(predictions_XG)\n",
    "                metrics_stake.append([rmse, mae, np.std(y['train2'])])\n",
    "                target_stake.append(y[\"test\"])\n",
    "                \n",
    "                # parameters:\n",
    "                params_stake.append([params_RF['learning_rate'], params_RF['n_estimators'], params_RF['max_depth']])\n",
    "\n",
    "        # Assemble for all stakes:\n",
    "        dfMetrics_xgb = pd.DataFrame(metrics_stake,\n",
    "                                     columns=['RMSE', 'MAE', 'std_obs'])\n",
    "        dfMetrics_xgb = dfMetrics_xgb[['RMSE', 'MAE', 'std_obs']] / (1000)\n",
    "\n",
    "        dfMetrics_xgb['stake'] = np.concatenate([[\n",
    "            stake.split('_')[0] + '_' + stake.split('_')[1]\n",
    "            for stake in glStakesExtreme[gl]\n",
    "        ] for gl in glStakesExtreme.keys()])\n",
    "        dfMetrics_xgb['stake'] = dfMetrics_xgb['stake'].apply(\n",
    "            lambda x: rename_stakes[x])\n",
    "        dfMetrics_xgb['glacier'] = np.concatenate(\n",
    "            [[gl] * len(glStakesExtreme[gl]) for gl in glStakesExtreme.keys()])\n",
    "        \n",
    "        dfParams_xgb = pd.DataFrame(params_stake, columns=['learning_rate', 'n_estimators', 'max_depth'])\n",
    "        dfParams_xgb['stake'] = np.concatenate([[\n",
    "            stake.split('_')[0] + '_' + stake.split('_')[1]\n",
    "            for stake in glStakesExtreme[gl]\n",
    "        ] for gl in glStakesExtreme.keys()])\n",
    "        dfParams_xgb['stake'] = dfParams_xgb['stake'].apply(\n",
    "            lambda x: rename_stakes[x])\n",
    "        dfParams_xgb['glacier'] = np.concatenate(\n",
    "            [[gl] * len(glStakesExtreme[gl]) for gl in glStakesExtreme.keys()])\n",
    "        \n",
    "        dfPred_xgb = pd.DataFrame(pred_stake, columns=test_index)\n",
    "        dfPred_xgb[['2023_target']] = target_stake\n",
    "        dfPred_xgb['stake'] = np.concatenate([[\n",
    "            stake.split('_')[0] + '_' + stake.split('_')[1]\n",
    "            for stake in glStakesExtreme[gl]\n",
    "        ] for gl in glStakesExtreme.keys()])\n",
    "        dfPred_xgb['stake'] = dfPred_xgb['stake'].apply(\n",
    "            lambda x: rename_stakes[x])\n",
    "        dfPred_xgb['glacier'] = np.concatenate(\n",
    "            [[gl] * len(glStakesExtreme[gl]) for gl in glStakesExtreme.keys()])\n",
    "\n",
    "        # Metrics on 2022 and 2023 alone:\n",
    "        dfMetrics_xgb['RMSE_2023'] = dfPred_xgb.apply(\n",
    "            lambda x: mean_squared_error([x[2023]], [x['2023_target']],\n",
    "                                         squared=False),\n",
    "            axis=1) / (1000)\n",
    "        dfMetrics_xgb['MAE_2023'] = dfPred_xgb.apply(\n",
    "            lambda x: mean_absolute_error([x[2023]], [x['2023_target']]),\n",
    "            axis=1) / (1000)\n",
    "\n",
    "        # Save to csv:\n",
    "        name_metrics = f'metrics_2023_{varcombi[0]}_{varcombi[1]}.csv'\n",
    "        print(f'Save {name_metrics} to {path_extreme}')\n",
    "        dfMetrics_xgb.to_csv(path_extreme + name_metrics)\n",
    "        name_pred = f'predictions_2023_{varcombi[0]}_{varcombi[1]}.csv'\n",
    "        print(f'Save {name_pred} to {path_extreme}')\n",
    "        dfPred_xgb.to_csv(path_extreme + name_pred)\n",
    "        name_params = f'params_2023_{varcombi[0]}_{varcombi[1]}.csv'\n",
    "        print(f'Save {name_params} to {path_extreme}')\n",
    "        dfParams_xgb.to_csv(path_extreme + name_params)\n",
    "\n",
    "# Tested on 2023 only:\n",
    "dfMetrics_xgb_2023 = pd.read_csv(path_extreme + 'metrics_2023_t2m_tp.csv')\n",
    "dfPred_xgb_2023 = pd.read_csv(path_extreme + 'predictions_2023_t2m_tp.csv')\n",
    "dfPred_xgb_2023.rename(columns={'2023': 2023}, inplace=True)\n",
    "dfPred_xgb_2023.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMetrics_xgb_2023.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tested on 2022:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on 2022 only:\n",
    "RUN = False\n",
    "possible_var = [['t2m', 'tp']]\n",
    "\n",
    "weights_t2m = np.ones(len(best_combi[0][0]))\n",
    "weights_tp = np.ones(len(best_combi[0][1]))\n",
    "\n",
    "if RUN:\n",
    "    for varcombi in possible_var:\n",
    "        print('Running for variables:', varcombi)\n",
    "        test_index = [2022]\n",
    "        pred_stake, metrics_stake, target_stake = [], [], []\n",
    "        for glacier in tqdm(glStakesExtreme.keys(), desc='glaciers'):\n",
    "            for stake in glStakesExtreme[glacier]:\n",
    "                stakeName = stake.split('_')[0] + '_' + stake.split('_')[1]\n",
    "                # print(f\"Processing {glacier} - {stakeName}\")\n",
    "                # Create input and target for model:\n",
    "                inputDF, target, xr_full = createSingleInput(best_combi,\n",
    "                                                             weights_t2m,\n",
    "                                                             weights_tp,\n",
    "                                                             stakeName,\n",
    "                                                             INPUT_TYPE,\n",
    "                                                             log=False,\n",
    "                                                             vars_=varcombi)\n",
    "\n",
    "                # Separate into training and testing:\n",
    "                X, y, time = createSingleInputArraysExtreme(test_index,\n",
    "                                                            target,\n",
    "                                                            inputDF,\n",
    "                                                            log=False)\n",
    "\n",
    "                # apply XGBoost model:\n",
    "                predictions_XG, val_loss, train_loss, epochs, best_iteration, params_RF = applySingleXGBoost(\n",
    "                    X, y, param_grid, log=False)\n",
    "                rmse, mae, pearson, rsquared2 = evalMetrics(\n",
    "                    y[\"test\"], predictions_XG)\n",
    "                pred_stake.append(predictions_XG)\n",
    "                metrics_stake.append([rmse, mae, np.std(y['train2'])])\n",
    "                target_stake.append(y[\"test\"])\n",
    "\n",
    "        # Assemble for all stakes:\n",
    "        dfMetrics_xgb = pd.DataFrame(metrics_stake,\n",
    "                                     columns=['RMSE', 'MAE', 'std_obs'])\n",
    "        dfMetrics_xgb = dfMetrics_xgb[['RMSE', 'MAE', 'std_obs']] / (1000)\n",
    "\n",
    "        dfMetrics_xgb['stake'] = np.concatenate([[\n",
    "            stake.split('_')[0] + '_' + stake.split('_')[1]\n",
    "            for stake in glStakesExtreme[gl]\n",
    "        ] for gl in glStakesExtreme.keys()])\n",
    "        dfMetrics_xgb['stake'] = dfMetrics_xgb['stake'].apply(\n",
    "            lambda x: rename_stakes[x])\n",
    "        dfMetrics_xgb['glacier'] = np.concatenate(\n",
    "            [[gl] * len(glStakesExtreme[gl]) for gl in glStakesExtreme.keys()])\n",
    "\n",
    "        dfPred_xgb = pd.DataFrame(pred_stake, columns=test_index)\n",
    "        dfPred_xgb[['2022_target']] = target_stake\n",
    "        dfPred_xgb['stake'] = np.concatenate([[\n",
    "            stake.split('_')[0] + '_' + stake.split('_')[1]\n",
    "            for stake in glStakesExtreme[gl]\n",
    "        ] for gl in glStakesExtreme.keys()])\n",
    "        dfPred_xgb['stake'] = dfPred_xgb['stake'].apply(\n",
    "            lambda x: rename_stakes[x])\n",
    "        dfPred_xgb['glacier'] = np.concatenate(\n",
    "            [[gl] * len(glStakesExtreme[gl]) for gl in glStakesExtreme.keys()])\n",
    "\n",
    "        # Metrics on 2022 and 2022 alone:\n",
    "        dfMetrics_xgb['RMSE_2022'] = dfPred_xgb.apply(\n",
    "            lambda x: mean_squared_error([x[2022]], [x['2022_target']],\n",
    "                                         squared=False),\n",
    "            axis=1) / (1000)\n",
    "        dfMetrics_xgb['MAE_2022'] = dfPred_xgb.apply(\n",
    "            lambda x: mean_absolute_error([x[2022]], [x['2022_target']]),\n",
    "            axis=1) / (1000)\n",
    "\n",
    "        # Save to csv:\n",
    "        name_metrics = f'metrics_2022_{varcombi[0]}_{varcombi[1]}.csv'\n",
    "        print(f'Save {name_metrics} to {path_extreme}')\n",
    "        dfMetrics_xgb.to_csv(path_extreme + name_metrics)\n",
    "        name_pred = f'predictions_2022_{varcombi[0]}_{varcombi[1]}.csv'\n",
    "        print(f'Save {name_pred} to {path_extreme}')\n",
    "        dfPred_xgb.to_csv(path_extreme + name_pred)\n",
    "\n",
    "# Tested on 2022 only:\n",
    "dfMetrics_xgb_2022 = pd.read_csv(path_extreme + 'metrics_2022_t2m_tp.csv')\n",
    "dfPred_xgb_2022 = pd.read_csv(path_extreme + 'predictions_2022_t2m_tp.csv')\n",
    "dfPred_xgb_2022.rename(columns={'2022': 2022}, inplace=True)\n",
    "dfPred_xgb_2022.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glaciers = list(glStakesExtreme.keys())\n",
    "RUN = False\n",
    "if RUN:\n",
    "    # Get surface height of stakes and era5/MS grid:\n",
    "    stake_grid_alt, stake_alt = getSurfaceHeight(glaciers,\n",
    "                                                 glStakesExtreme,\n",
    "                                                 input_type=INPUT_TYPE)\n",
    "\n",
    "    # Get temperature gradients:\n",
    "    print('Constructing temperature gradients from ERA5:')\n",
    "    dTdz_stakes = getTemperatureGradients(glaciers, glStakesExtreme)\n",
    "\n",
    "# Initial values\n",
    "SUR_0, SNOW_0, BAL_0 = 0, 0, 0  # start as ice\n",
    "dPdz = 1 / 10000  # % increase/100m constant for now changed to unit/m\n",
    "\n",
    "c_prec = 1.5  # []\n",
    "DDFsnow, DDFice = 3 / 1000, 6 / 1000  # constant [m d-1 K-1]\n",
    "\n",
    "inital_params = {\n",
    "    'sur0': SUR_0,\n",
    "    'sno0': SNOW_0,\n",
    "    'bal0': BAL_0,\n",
    "}\n",
    "\n",
    "# CALIBRATION:\n",
    "# Range of parameters to fit during round 1 (cprec) and round 2 (DDFsnow)\n",
    "DDFsnow_range = np.linspace(1 / (1000), 10 / (1000), 25)\n",
    "c_prec_range = np.linspace(0.8, 4, 25)\n",
    "\n",
    "weights_t2m_pdd = np.ones(len(best_combi[0][0]))\n",
    "weights_tp_pdd = np.ones(len(best_combi[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tested on 2022 and 2023:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN = False\n",
    "if RUN:\n",
    "    test_years = [2022, 2023]\n",
    "    vars_ = ['t2m', 'tp']\n",
    "\n",
    "    pred_stake_ann, pred_stake_win, metrics_stake_pdd, target_pdd,  = [], [], [], []\n",
    "    c_stake, DDF_stake = {}, {}\n",
    "    for glacier in tqdm(glStakesExtreme.keys(), desc='glaciers'):\n",
    "        for stake in glStakesExtreme[glacier]:\n",
    "            stakeName = stake.split('_')[0] + '_' + stake.split('_')[1]\n",
    "            # print(f\"Processing {glacier} - {stakeName}\")\n",
    "\n",
    "            # Get target and input:\n",
    "            el_stake = stake_alt[stakeName]\n",
    "            el_grid = stake_grid_alt[stakeName]\n",
    "            constants = {\n",
    "                \"dPdz\": dPdz,\n",
    "                \"el_stake\": round(el_stake, 3),\n",
    "                \"el_grid\": round(el_grid, 3),\n",
    "            }\n",
    "\n",
    "            # Create input and target for model:\n",
    "            inputDF, target, xr_full = createSingleInput(best_combi,\n",
    "                                                         weights_t2m_pdd,\n",
    "                                                         weights_tp_pdd,\n",
    "                                                         stakeName,\n",
    "                                                         INPUT_TYPE,\n",
    "                                                         log=False,\n",
    "                                                         vars_=vars_)\n",
    "\n",
    "            # Separate into training and testing\n",
    "            ann_mb, w_mb, time_pdd = createSingleInputArraysExtreme_PDD(\n",
    "                target, test_years, seed=SEED)\n",
    "\n",
    "            pred_pdd_w, pred_pdd_ann, c_year, DDFsnow_year = applySinglePDD(\n",
    "                stake,\n",
    "                xr_full,\n",
    "                time_pdd,\n",
    "                ann_mb,\n",
    "                w_mb,\n",
    "                dTdz_stakes,\n",
    "                dPdz,\n",
    "                c_prec,\n",
    "                DDFsnow,\n",
    "                DDFice,\n",
    "                DDFsnow_range,\n",
    "                c_prec_range,\n",
    "                inital_params,\n",
    "                constants,\n",
    "                input_type=INPUT_TYPE)\n",
    "\n",
    "            # Save PDD parameters:\n",
    "            c_stake[stakeName] = c_year\n",
    "            DDF_stake[stakeName] = DDFsnow_year\n",
    "\n",
    "            rmse_pdd, mae_pdd, pearson_pdd, rsquared2_pdd = evalMetrics(\n",
    "                ann_mb[\"test\"], pred_pdd_ann)\n",
    "\n",
    "            # Save:\n",
    "            pred_stake_ann.append(pred_pdd_ann)\n",
    "            pred_stake_win.append(pred_pdd_w)\n",
    "            metrics_stake_pdd.append(\n",
    "                [rmse_pdd, mae_pdd, pearson_pdd, rsquared2_pdd])\n",
    "            target_pdd.append(ann_mb[\"test\"])\n",
    "\n",
    "    # Assemble for all stakes:\n",
    "    dfMetrics_pdd = pd.DataFrame(metrics_stake_pdd,\n",
    "                                 columns=['RMSE', 'MAE', 'Pearson', 'R2'])\n",
    "    dfMetrics_pdd = dfMetrics_pdd[['RMSE', 'MAE']] / (1000)\n",
    "    dfMetrics_pdd['stake'] = np.concatenate([[\n",
    "        stake.split('_')[0] + '_' + stake.split('_')[1]\n",
    "        for stake in glStakesExtreme[gl]\n",
    "    ] for gl in glStakesExtreme.keys()])\n",
    "    dfMetrics_pdd['stake'] = dfMetrics_pdd['stake'].apply(\n",
    "        lambda x: rename_stakes[x])\n",
    "    dfMetrics_pdd['glacier'] = np.concatenate(\n",
    "        [[gl] * len(glStakesExtreme[gl]) for gl in glStakesExtreme.keys()])\n",
    "\n",
    "    dfPred_pdd = pd.DataFrame(pred_stake_ann, columns=test_years)\n",
    "    dfPred_pdd[['2022_target', '2023_target']] = target_pdd\n",
    "    dfPred_pdd['stake'] = np.concatenate([[\n",
    "        stake.split('_')[0] + '_' + stake.split('_')[1]\n",
    "        for stake in glStakesExtreme[gl]\n",
    "    ] for gl in glStakesExtreme.keys()])\n",
    "    dfPred_pdd['stake'] = dfPred_pdd['stake'].apply(lambda x: rename_stakes[x])\n",
    "    dfPred_pdd['glacier'] = np.concatenate([[gl] * len(glStakesExtreme[gl])\n",
    "                                            for gl in glStakesExtreme.keys()])\n",
    "\n",
    "    # Metrics on 2022 and 2023 alone:\n",
    "    dfMetrics_pdd['RMSE_2022'] = dfPred_pdd.apply(lambda x: mean_squared_error(\n",
    "        [x[2022]], [x['2022_target']], squared=False),\n",
    "                                                  axis=1) / (1000)\n",
    "    dfMetrics_pdd['RMSE_2023'] = dfPred_pdd.apply(lambda x: mean_squared_error(\n",
    "        [x[2023]], [x['2023_target']], squared=False),\n",
    "                                                  axis=1) / (1000)\n",
    "    dfMetrics_pdd['MAE_2022'] = dfPred_pdd.apply(\n",
    "        lambda x: mean_absolute_error([x[2022]], [x['2022_target']]),\n",
    "        axis=1) / (1000)\n",
    "    dfMetrics_pdd['MAE_2023'] = dfPred_pdd.apply(\n",
    "        lambda x: mean_absolute_error([x[2023]], [x['2023_target']]),\n",
    "        axis=1) / (1000)\n",
    "\n",
    "    # Parameter range:\n",
    "    with open(path_extreme + f\"c_2022_2023.pkl\", \"wb\") as fp:\n",
    "        pickle.dump(c_stake, fp)\n",
    "    with open(path_extreme + f\"DDF_2022_2023.pkl\", \"wb\") as fp:\n",
    "        pickle.dump(DDF_stake, fp)\n",
    "\n",
    "    # save to csv:\n",
    "    dfMetrics_pdd.to_csv(path_extreme + 'metrics_pdd_2022_2023.csv')\n",
    "    dfPred_pdd.to_csv(path_extreme + 'predictions_pdd_2022_2023.csv')\n",
    "\n",
    "# Tested on 2022 and 2023:\n",
    "dfMetrics_pdd_2022_2023 = pd.read_csv(path_extreme +\n",
    "                                      'metrics_pdd_2022_2023.csv')\n",
    "dfPred_pdd_2022_2023 = pd.read_csv(path_extreme +\n",
    "                                   'predictions_pdd_2022_2023.csv')\n",
    "dfPred_pdd_2022_2023.rename(columns={'2023': 2023, '2022': 2022}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tested on 2022:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022 only:\n",
    "RUN = False\n",
    "if RUN:\n",
    "    vars_ = ['t2m', 'tp']\n",
    "    test_years = [2022]\n",
    "    pred_stake_ann, pred_stake_win, metrics_stake_pdd, target_pdd = [], [], [], []\n",
    "    for glacier in tqdm(glStakesExtreme.keys(), desc='glaciers'):\n",
    "        for stake in glStakesExtreme[glacier]:\n",
    "            stakeName = stake.split('_')[0] + '_' + stake.split('_')[1]\n",
    "            # print(f\"Processing {glacier} - {stakeName}\")\n",
    "\n",
    "            # Get target and input:\n",
    "            el_stake = stake_alt[stakeName]\n",
    "            el_grid = stake_grid_alt[stakeName]\n",
    "            constants = {\n",
    "                \"dPdz\": dPdz,\n",
    "                \"el_stake\": round(el_stake, 3),\n",
    "                \"el_grid\": round(el_grid, 3),\n",
    "            }\n",
    "\n",
    "            # Create input and target for model:\n",
    "            inputDF, target, xr_full = createSingleInput(best_combi,\n",
    "                                                         weights_t2m_pdd,\n",
    "                                                         weights_tp_pdd,\n",
    "                                                         stakeName,\n",
    "                                                         INPUT_TYPE,\n",
    "                                                         log=False,\n",
    "                                                         vars_=vars_)\n",
    "\n",
    "            # Separate into training and testing\n",
    "            ann_mb, w_mb, time_pdd = createSingleInputArraysExtreme_PDD(\n",
    "                target, test_years, seed=SEED)\n",
    "\n",
    "            pred_pdd_w, pred_pdd_ann, c_year, DDFsnow_year = applySinglePDD(\n",
    "                stake,\n",
    "                xr_full,\n",
    "                time_pdd,\n",
    "                ann_mb,\n",
    "                w_mb,\n",
    "                dTdz_stakes,\n",
    "                dPdz,\n",
    "                c_prec,\n",
    "                DDFsnow,\n",
    "                DDFice,\n",
    "                DDFsnow_range,\n",
    "                c_prec_range,\n",
    "                inital_params,\n",
    "                constants,\n",
    "                input_type=INPUT_TYPE)\n",
    "\n",
    "            rmse_pdd, mae_pdd, pearson_pdd, rsquared2_pdd = evalMetrics(\n",
    "                ann_mb[\"test\"], pred_pdd_ann)\n",
    "\n",
    "            # Save:\n",
    "            pred_stake_ann.append(pred_pdd_ann)\n",
    "            pred_stake_win.append(pred_pdd_w)\n",
    "            metrics_stake_pdd.append(\n",
    "                [rmse_pdd, mae_pdd, pearson_pdd, rsquared2_pdd])\n",
    "            target_pdd.append(ann_mb[\"test\"])\n",
    "\n",
    "    # Assemble for all stakes:\n",
    "    dfMetrics_pdd = pd.DataFrame(metrics_stake_pdd,\n",
    "                                 columns=['RMSE', 'MAE', 'Pearson', 'R2'])\n",
    "    dfMetrics_pdd = dfMetrics_pdd[['RMSE', 'MAE']] / (1000)\n",
    "    dfMetrics_pdd['stake'] = np.concatenate([[\n",
    "        stake.split('_')[0] + '_' + stake.split('_')[1]\n",
    "        for stake in glStakesExtreme[gl]\n",
    "    ] for gl in glStakesExtreme.keys()])\n",
    "    dfMetrics_pdd['stake'] = dfMetrics_pdd['stake'].apply(\n",
    "        lambda x: rename_stakes[x])\n",
    "    dfMetrics_pdd['glacier'] = np.concatenate(\n",
    "        [[gl] * len(glStakesExtreme[gl]) for gl in glStakesExtreme.keys()])\n",
    "    dfPred_pdd = pd.DataFrame(pred_stake_ann, columns=test_years)\n",
    "    dfPred_pdd[['2022_target']] = target_pdd\n",
    "    dfPred_pdd['stake'] = np.concatenate([[\n",
    "        stake.split('_')[0] + '_' + stake.split('_')[1]\n",
    "        for stake in glStakesExtreme[gl]\n",
    "    ] for gl in glStakesExtreme.keys()])\n",
    "    dfPred_pdd['stake'] = dfPred_pdd['stake'].apply(lambda x: rename_stakes[x])\n",
    "    dfPred_pdd['glacier'] = np.concatenate([[gl] * len(glStakesExtreme[gl])\n",
    "                                            for gl in glStakesExtreme.keys()])\n",
    "\n",
    "    # Metrics on 2022 alone:\n",
    "    dfMetrics_pdd['RMSE_2022'] = dfPred_pdd.apply(lambda x: mean_squared_error(\n",
    "        [x[2022]], [x['2022_target']], squared=False),\n",
    "                                                  axis=1) / (1000)\n",
    "    dfMetrics_pdd['MAE_2022'] = dfPred_pdd.apply(\n",
    "        lambda x: mean_absolute_error([x[2022]], [x['2022_target']]),\n",
    "        axis=1) / (1000)\n",
    "\n",
    "    # save to csv:\n",
    "    dfMetrics_pdd.to_csv(path_extreme + 'metrics_pdd_2022.csv')\n",
    "    dfPred_pdd.to_csv(path_extreme + 'predictions_pdd_2022.csv')\n",
    "\n",
    "# Tested on 2022 and 2022:\n",
    "dfMetrics_pdd_2022 = pd.read_csv(path_extreme + 'metrics_pdd_2022.csv')\n",
    "dfPred_pdd_2022 = pd.read_csv(path_extreme + 'predictions_pdd_2022.csv')\n",
    "dfPred_pdd_2022.rename(columns={'2022': 2022}, inplace=True)\n",
    "dfMetrics_pdd_2022.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tested on 2023:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023 only:\n",
    "RUN = False\n",
    "if RUN:\n",
    "    vars_ = ['t2m', 'tp']\n",
    "    test_years = [2023]\n",
    "    pred_stake_ann, pred_stake_win, metrics_stake_pdd, target_pdd = [], [], [], []\n",
    "    for glacier in tqdm(glStakesExtreme.keys(), desc='glaciers'):\n",
    "        for stake in glStakesExtreme[glacier]:\n",
    "            stakeName = stake.split('_')[0] + '_' + stake.split('_')[1]\n",
    "            # print(f\"Processing {glacier} - {stakeName}\")\n",
    "\n",
    "            # Get target and input:\n",
    "            el_stake = stake_alt[stakeName]\n",
    "            el_grid = stake_grid_alt[stakeName]\n",
    "            constants = {\n",
    "                \"dPdz\": dPdz,\n",
    "                \"el_stake\": round(el_stake, 3),\n",
    "                \"el_grid\": round(el_grid, 3),\n",
    "            }\n",
    "\n",
    "            # Create input and target for model:\n",
    "            inputDF, target, xr_full = createSingleInput(best_combi,\n",
    "                                                         weights_t2m_pdd,\n",
    "                                                         weights_tp_pdd,\n",
    "                                                         stakeName,\n",
    "                                                         INPUT_TYPE,\n",
    "                                                         log=False,\n",
    "                                                         vars_=vars_)\n",
    "\n",
    "            # Separate into training and testing\n",
    "            ann_mb, w_mb, time_pdd = createSingleInputArraysExtreme_PDD(\n",
    "                target, test_years, seed=SEED)\n",
    "\n",
    "            pred_pdd_w, pred_pdd_ann, c_year, DDFsnow_year = applySinglePDD(\n",
    "                stake,\n",
    "                xr_full,\n",
    "                time_pdd,\n",
    "                ann_mb,\n",
    "                w_mb,\n",
    "                dTdz_stakes,\n",
    "                dPdz,\n",
    "                c_prec,\n",
    "                DDFsnow,\n",
    "                DDFice,\n",
    "                DDFsnow_range,\n",
    "                c_prec_range,\n",
    "                inital_params,\n",
    "                constants,\n",
    "                input_type=INPUT_TYPE)\n",
    "\n",
    "            rmse_pdd, mae_pdd, pearson_pdd, rsquared2_pdd = evalMetrics(\n",
    "                ann_mb[\"test\"], pred_pdd_ann)\n",
    "\n",
    "            # Save:\n",
    "            pred_stake_ann.append(pred_pdd_ann)\n",
    "            pred_stake_win.append(pred_pdd_w)\n",
    "            metrics_stake_pdd.append(\n",
    "                [rmse_pdd, mae_pdd, pearson_pdd, rsquared2_pdd])\n",
    "            target_pdd.append(ann_mb[\"test\"])\n",
    "\n",
    "    # Assemble for all stakes:\n",
    "    dfMetrics_pdd = pd.DataFrame(metrics_stake_pdd,\n",
    "                                 columns=['RMSE', 'MAE', 'Pearson', 'R2'])\n",
    "    dfMetrics_pdd = dfMetrics_pdd[['RMSE', 'MAE']] / (1000)\n",
    "    dfMetrics_pdd['stake'] = np.concatenate([[\n",
    "        stake.split('_')[0] + '_' + stake.split('_')[1]\n",
    "        for stake in glStakesExtreme[gl]\n",
    "    ] for gl in glStakesExtreme.keys()])\n",
    "    dfMetrics_pdd['stake'] = dfMetrics_pdd['stake'].apply(\n",
    "        lambda x: rename_stakes[x])\n",
    "    dfMetrics_pdd['glacier'] = np.concatenate(\n",
    "        [[gl] * len(glStakesExtreme[gl]) for gl in glStakesExtreme.keys()])\n",
    "    dfPred_pdd = pd.DataFrame(pred_stake_ann, columns=test_years)\n",
    "    dfPred_pdd[['2023_target']] = target_pdd\n",
    "    dfPred_pdd['stake'] = np.concatenate([[\n",
    "        stake.split('_')[0] + '_' + stake.split('_')[1]\n",
    "        for stake in glStakesExtreme[gl]\n",
    "    ] for gl in glStakesExtreme.keys()])\n",
    "    dfPred_pdd['stake'] = dfPred_pdd['stake'].apply(lambda x: rename_stakes[x])\n",
    "    dfPred_pdd['glacier'] = np.concatenate([[gl] * len(glStakesExtreme[gl])\n",
    "                                            for gl in glStakesExtreme.keys()])\n",
    "\n",
    "    # Metrics on 2023 alone:\n",
    "    dfMetrics_pdd['RMSE_2023'] = dfPred_pdd.apply(lambda x: mean_squared_error(\n",
    "        [x[2023]], [x['2023_target']], squared=False),\n",
    "                                                  axis=1) / (1000)\n",
    "    dfMetrics_pdd['MAE_2023'] = dfPred_pdd.apply(\n",
    "        lambda x: mean_absolute_error([x[2023]], [x['2023_target']]),\n",
    "        axis=1) / (1000)\n",
    "\n",
    "    # save to csv:\n",
    "    dfMetrics_pdd.to_csv(path_extreme + 'metrics_pdd_2023.csv')\n",
    "    dfPred_pdd.to_csv(path_extreme + 'predictions_pdd_2023.csv')\n",
    "\n",
    "# Tested on 2022 and 2023:\n",
    "dfMetrics_pdd_2023 = pd.read_csv(path_extreme + 'metrics_pdd_2023.csv')\n",
    "dfPred_pdd_2023 = pd.read_csv(path_extreme + 'predictions_pdd_2023.csv')\n",
    "dfPred_pdd_2023.rename(columns={'2023': 2023}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tested on 2022 and 2023:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PDD Parameter range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pkl files:\n",
    "with open(path_extreme + f\"c_2022_2023.pkl\", \"rb\") as fp:\n",
    "    c_stake = pickle.load(fp)\n",
    "with open(path_extreme + f\"DDF_2022_2023.pkl\", \"rb\") as fp:\n",
    "    DDF_stake = pickle.load(fp)\n",
    "\n",
    "param_df = pd.DataFrame(np.concatenate(list(c_stake.values())), columns=['c'])\n",
    "stakes = []\n",
    "for key in c_stake.keys():\n",
    "    stakes.append(np.tile(key, len(c_stake[key])))\n",
    "param_df['stake'] = np.concatenate(stakes)\n",
    "param_df['stake'] = param_df['stake'].apply(lambda x: rename_stakes[x])\n",
    "param_df['DDF'] = np.concatenate(list(DDF_stake.values()))\n",
    "param_df['glacier'] = param_df.stake.apply(lambda x: x.split('-')[0])\n",
    "param_df['stakes_full'] = param_df.glacier.apply(lambda x: GL_SHORT[\n",
    "    x]) + '-' + param_df.stake.apply(lambda x: x.split('-')[1])\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "ax = plt.subplot(2, 2, 1)\n",
    "sns.boxplot(param_df, x='stakes_full', y='c', ax=ax, color=color_diff_xgbplus)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),\n",
    "                   rotation=90,\n",
    "                   horizontalalignment='right')\n",
    "ax.set_title('Param c', fontsize=18)\n",
    "\n",
    "ax = plt.subplot(2, 2, 2)\n",
    "sns.boxplot(param_df,\n",
    "            x='stakes_full',\n",
    "            y='DDF',\n",
    "            ax=ax,\n",
    "            color=color_diff_xgbplus)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),\n",
    "                   rotation=90,\n",
    "                   horizontalalignment='right')\n",
    "ax.set_title('Param DDF snow', fontsize=18)\n",
    "\n",
    "for ax in fig.get_axes():\n",
    "    ax.set_xlabel('Stakes', fontsize=18)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference to TIM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stakes_extrm_2022 = [\n",
    "    'ALE-P4', 'ALL-P1', 'BAS-P1', 'BAS-P2', 'BAS-P3', 'CLA-P1', 'CLA-P2',\n",
    "    'COR-P1', 'GIE-P1', 'GIE-P2', 'GIE-P3', 'GRI-P1', 'GRI-P2', 'HOH-P1',\n",
    "    'SCH-P1', 'SIL-P2', 'SIL-P3'\n",
    "]\n",
    "\n",
    "stakes_extrm_2023 = [\n",
    "    'ALL-P1',\n",
    "    'BAS-P1',\n",
    "    'BAS-P3',\n",
    "    'CLA-P1',\n",
    "    'COR-P1',\n",
    "    'GRI-P1',\n",
    "    'GRI-P2',\n",
    "    'HOH-P1',\n",
    "    'PERS-P1',\n",
    "    'SCH-P1',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addExtrm(df, stakes_extrm_2022, stakes_extrm_2023):\n",
    "    is_extrm_2022, is_extrm_2023 = [], []\n",
    "    for stake in df.stakes_full:\n",
    "        is_extrm_2022.append(stake in stakes_extrm_2022)\n",
    "        is_extrm_2023.append(stake in stakes_extrm_2023)\n",
    "    df['is_extrm_2022'] = is_extrm_2022\n",
    "    df['is_extrm_2023'] = is_extrm_2023\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all csv:\n",
    "# 2022 and 2023:\n",
    "dfMetrics_pdd_2022_2023 = pd.read_csv(path_extreme +\n",
    "                                      'metrics_pdd_2022_2023.csv')\n",
    "dfMetrics_xgb_2022_2023 = pd.read_csv(path_extreme +\n",
    "                                      f'metrics_2022_2023_t2m_tp.csv')\n",
    "dfDiffMetrics_2022_2023 = CreateDiffMetrics_xtr(dfMetrics_xgb_2022_2023,\n",
    "                                                dfMetrics_pdd_2022_2023)\n",
    "dfDiffMetrics_2022_2023 = addExtrm(dfDiffMetrics_2022_2023, stakes_extrm_2022,\n",
    "                                   stakes_extrm_2023)\n",
    "dfDiffMetrics_2022_2023['training'] = '2021'\n",
    "dfDiffMetrics_2022_2023.sort_values(by='stakes_full', inplace=True)\n",
    "\n",
    "# Only 2023:\n",
    "dfMetrics_xgb_2023 = pd.read_csv(path_extreme + f'metrics_2023_t2m_tp.csv')\n",
    "dfMetrics_pdd_2023 = pd.read_csv(path_extreme + 'metrics_pdd_2023.csv')\n",
    "dfDiffMetrics_2023 = pd.merge(dfMetrics_xgb_2023.drop(['Unnamed: 0'], axis=1),\n",
    "                              dfMetrics_pdd_2023.drop(['Unnamed: 0'], axis=1),\n",
    "                              on='stake',\n",
    "                              suffixes=('_xgb', '_pdd'))\n",
    "dfDiffMetrics_2023['diff_mae_2023'] = dfDiffMetrics_2023[\n",
    "    'MAE_xgb'] - dfDiffMetrics_2023['MAE_pdd']\n",
    "dfDiffMetrics_2023['diff_mae_2023_wrt_to_std'] = dfDiffMetrics_2023[\n",
    "    'diff_mae_2023'] / np.abs(dfDiffMetrics_2023['std_obs'])\n",
    "dfDiffMetrics_2023['stakes_full'] = dfDiffMetrics_2023.stake.apply(\n",
    "    lambda x: GL_SHORT[x.split('-')[\n",
    "        0]]) + '-' + dfDiffMetrics_2023.stake.apply(lambda x: x.split('-')[1])\n",
    "dfDiffMetrics_2023 = addExtrm(dfDiffMetrics_2023, stakes_extrm_2022,\n",
    "                              stakes_extrm_2023)\n",
    "dfDiffMetrics_2023['training'] = '2022'\n",
    "dfDiffMetrics_2023.sort_values(by='stakes_full', inplace=True)\n",
    "\n",
    "dfDiffMetrics_all = pd.concat([dfDiffMetrics_2022_2023, dfDiffMetrics_2023],\n",
    "                              axis=0).sort_values(by='stakes_full')[[\n",
    "                                  'stakes_full', 'diff_mae_2023',\n",
    "                                  'diff_mae_2023_wrt_to_std',\n",
    "                                  'is_extrm_2023','training','std_obs'\n",
    "                              ]]\n",
    "dfDiffMetrics_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDiffMetrics_all[dfDiffMetrics_all.stakes_full == 'SCH-P1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fig 9: Prediction of extreme years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_extremes = sns.color_palette([color_diff_xgbplus, '#8f3d7f'])\n",
    "alpha = 0.8\n",
    "fontsize_title = 22\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharey=True)\n",
    "\n",
    "# Diff MAE:\n",
    "g = sns.barplot(\n",
    "    dfDiffMetrics_2022_2023,\n",
    "    x='stakes_full',\n",
    "    #y=f'diff_mae_2022',\n",
    "    y = 'diff_mae_2022_wrt_to_std',\n",
    "    ax=ax1,\n",
    "    dodge=False,\n",
    "    hue='is_extrm_2022',\n",
    "    palette=palette_extremes,\n",
    "    alpha=alpha,\n",
    ")\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=90)\n",
    "\n",
    "# Diff MAE:\n",
    "g = sns.barplot(\n",
    "    dfDiffMetrics_all,\n",
    "    x='stakes_full',\n",
    "    #y=f'diff_mae_2023',\n",
    "    y = 'diff_mae_2023_wrt_to_std',\n",
    "    ax=ax2,\n",
    "    hue='training',\n",
    "    palette=palette_extremes,\n",
    "    alpha=alpha,\n",
    ")\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation=90)\n",
    "num_locations = len(dfDiffMetrics_all.stakes_full.unique())\n",
    "# hatches = itertools.cycle(['/', '//', '+', '-', 'x', '\\\\', '*', 'o', 'O', '.'])\n",
    "hatch = '//'\n",
    "for i, bar in enumerate(ax2.patches):\n",
    "    value = bar.get_height()\n",
    "    training = dfDiffMetrics_all.iloc[(\n",
    "        dfDiffMetrics_all['diff_mae_2023_wrt_to_std'] -\n",
    "        value).abs().argsort()[:1]].training.values[0]\n",
    "    if training == '2022':\n",
    "        bar.set_hatch(hatch)\n",
    "    # find location in dataframe:\n",
    "    isextrm = dfDiffMetrics_all.iloc[(\n",
    "        dfDiffMetrics_all['diff_mae_2023_wrt_to_std'] -\n",
    "        value).abs().argsort()[:1]].is_extrm_2023.values\n",
    "    if isextrm:\n",
    "        bar.set_color(palette_extremes[1])\n",
    "    else:\n",
    "        bar.set_color(palette_extremes[0])\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.legend([], [], frameon=False)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=18)\n",
    "    ax.set_title(f'')\n",
    "    #ax.set_ylabel('[m w.e.]', fontsize=18)\n",
    "    ax.set_ylabel('% w.r.t std of observed PMB ', fontsize=18)\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "\n",
    "ax2.legend(title='Last year of training dataset',\n",
    "           fontsize=\"20\",\n",
    "           bbox_to_anchor=(1.05, 1),\n",
    "           loc=2,\n",
    "           ncol=1,\n",
    "           fancybox=True,\n",
    "           shadow=False,\n",
    "           frameon=False)\n",
    "ax1.legend(title='Year is exreme',\n",
    "           fontsize=\"20\",\n",
    "           bbox_to_anchor=(1.05, 1),\n",
    "           loc=2,\n",
    "           ncol=1,\n",
    "           fancybox=True,\n",
    "           shadow=False,\n",
    "           frameon=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDiffMetrics_all[dfDiffMetrics_all.stakes_full == 'BAS-P3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fig A2: all stakes without param range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARS = ['t2m', 'tp']\n",
    "dfMetrics_xgb = pd.read_csv(path_extreme +\n",
    "                            f'metrics_2022_2023_{VARS[0]}_{VARS[1]}.csv')\n",
    "dfPred_xgb_2022_2023 = pd.read_csv(path_extreme +\n",
    "                         f'predictions_2022_2023_{VARS[0]}_{VARS[1]}.csv')\n",
    "dfPred_xgb_2022_2023.rename(columns={'2023': 2023, '2022': 2022}, inplace=True)\n",
    "\n",
    "stakesExtreme.sort()\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "M, N = 5, 2\n",
    "for i, stake_old in enumerate(stakesExtreme[:10]):\n",
    "    ax = plt.subplot(M, N, i + 1)\n",
    "    stake_new = rename_stakes[stake_old]\n",
    "    plotPredStake(stake_new, stake_old, weights_t2m, weights_tp,\n",
    "                  dfMetrics_pdd_2022_2023, dfMetrics_xgb_2022_2023,\n",
    "                  dfPred_pdd_2022_2023, dfPred_xgb_2022_2023, best_combi, ax,\n",
    "                  INPUT_TYPE, color_xgb, color_tim, marker_xgb, marker_tim,\n",
    "                  VARS)\n",
    "\n",
    "    ax.set_xlabel('')\n",
    "    # ax.set_ylabel('[m w.e.]')\n",
    "    ax.set_ylabel('')\n",
    "    ax.legend([], [], frameon=False)\n",
    "    ax.set_title(stake_new)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 10))\n",
    "M, N = 5, 2\n",
    "for i, stake_old in enumerate(stakesExtreme[10:]):\n",
    "    ax = plt.subplot(M, N, i + 1)\n",
    "    stake_new = rename_stakes[stake_old]\n",
    "    plotPredStake(stake_new, stake_old, weights_t2m, weights_tp,\n",
    "                  dfMetrics_pdd_2022_2023, dfMetrics_xgb_2022_2023,\n",
    "                  dfPred_pdd_2022_2023, dfPred_xgb_2022_2023, best_combi, ax,\n",
    "                  INPUT_TYPE, color_xgb, color_tim, marker_xgb, marker_tim,\n",
    "                  VARS)\n",
    "\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.legend([], [], frameon=False)\n",
    "    ax.set_title(stake_new)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tested on 2023:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_var = [['t2m', 'tp']]\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "M, N = 1, 2\n",
    "alpha = 0.8\n",
    "fontsize_title = 22\n",
    "\n",
    "for i, VARS in enumerate(possible_var):\n",
    "    vars_ = f'climate variables {VARS[0]} & {VARS[1]}'\n",
    "    dfMetrics_xgb = pd.read_csv(path_extreme +\n",
    "                                f'metrics_2023_{VARS[0]}_{VARS[1]}.csv')\n",
    "    dfPred_xgb = pd.read_csv(path_extreme +\n",
    "                             f'predictions_2023_{VARS[0]}_{VARS[1]}.csv')\n",
    "    dfPred_xgb.rename(columns={'2023': 2023}, inplace=True)\n",
    "\n",
    "    dfDiffMetrics_2023 = pd.merge(dfMetrics_xgb.drop(['Unnamed: 0'], axis=1),\n",
    "                                  dfMetrics_pdd_2023.drop(['Unnamed: 0'],\n",
    "                                                          axis=1),\n",
    "                                  on='stake',\n",
    "                                  suffixes=('_xgb', '_pdd'))\n",
    "    dfDiffMetrics_2023['diff_mae'] = dfDiffMetrics_2023[\n",
    "        'MAE_xgb'] - dfDiffMetrics_2023['MAE_pdd']\n",
    "\n",
    "    dfDiffMetrics_2023['stakes_full'] = dfDiffMetrics_2023.stake.apply(\n",
    "        lambda x: GL_SHORT[x.split('-')[0]]\n",
    "    ) + '-' + dfDiffMetrics_2023.stake.apply(lambda x: x.split('-')[1])\n",
    "\n",
    "    dfDiffMetrics_2023.sort_values(by='stakes_full', inplace=True)\n",
    "\n",
    "    # Diff MAE both:\n",
    "    ax1 = plt.subplot(M, N, i + 1)\n",
    "    g = sns.barplot(\n",
    "        dfDiffMetrics_2023,\n",
    "        x='stakes_full',\n",
    "        y=f'diff_mae',\n",
    "        ax=ax1,\n",
    "        dodge=False,\n",
    "        color=color_diff_xgbplus,\n",
    "        alpha=alpha,\n",
    "    )\n",
    "    h, l = g.get_legend_handles_labels()\n",
    "    ax1.set_xticklabels(ax1.get_xticklabels(), rotation=90)\n",
    "    ax1.set_ylabel('[m w.e. a$^{-1}$]', fontsize=18)\n",
    "    ax1.set_title(f'2023', fontsize=fontsize_title)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_var = ['t2m', 'tp']\n",
    "palette_extremes = sns.color_palette([color_diff_xgbplus, '#8f3d7f'])\n",
    "\n",
    "dfMetrics_xgb_2023 = pd.read_csv(\n",
    "    path_extreme + f'metrics_2023_{possible_var[0]}_{possible_var[1]}.csv')\n",
    "dfMetrics_pdd_2023 = pd.read_csv(path_extreme + 'metrics_pdd_2023.csv')\n",
    "\n",
    "dfDiffMetrics_2023 = pd.merge(dfMetrics_xgb_2023.drop(['Unnamed: 0'], axis=1),\n",
    "                              dfMetrics_pdd_2023.drop(['Unnamed: 0'], axis=1),\n",
    "                              on='stake',\n",
    "                              suffixes=('_xgb', '_pdd'))\n",
    "dfDiffMetrics_2023['diff_mae_2023'] = dfDiffMetrics_2023[\n",
    "    'MAE_xgb'] - dfDiffMetrics_2023['MAE_pdd']\n",
    "\n",
    "dfDiffMetrics_2023['stakes_full'] = dfDiffMetrics_2023.stake.apply(\n",
    "    lambda x: GL_SHORT[x.split('-')[\n",
    "        0]]) + '-' + dfDiffMetrics_2023.stake.apply(lambda x: x.split('-')[1])\n",
    "\n",
    "is_extrm_2023 = []\n",
    "for stake in dfDiffMetrics_2023.stakes_full:\n",
    "    is_extrm_2023.append(stake in stakes_extrm_2023)\n",
    "dfDiffMetrics_2023['is_extrm_2023'] = is_extrm_2023\n",
    "dfDiffMetrics_2023.sort_values(by='stakes_full', inplace=True)\n",
    "\n",
    "dfPred_xgb = pd.read_csv(\n",
    "    path_extreme + f'predictions_2023_{possible_var[0]}_{possible_var[1]}.csv')\n",
    "dfPred_xgb['stakes_full'] = dfPred_xgb.stake.apply(lambda x: GL_SHORT[x.split(\n",
    "    '-')[0]]) + '-' + dfPred_xgb.stake.apply(lambda x: x.split('-')[1])\n",
    "\n",
    "dfPred_pdd = pd.read_csv(path_extreme + f'predictions_pdd_2023.csv')\n",
    "dfPred_pdd['stakes_full'] = dfPred_pdd.stake.apply(lambda x: GL_SHORT[x.split(\n",
    "    '-')[0]]) + '-' + dfPred_pdd.stake.apply(lambda x: x.split('-')[1])\n",
    "is_extrm_2023 = []\n",
    "for stake in dfPred_xgb.stakes_full:\n",
    "    is_extrm_2023.append(stake in stakes_extrm_2023)\n",
    "dfPred_xgb['is_extrm_2023'] = is_extrm_2023\n",
    "\n",
    "# change from mm to m\n",
    "dfPred_pdd['2023'] = dfPred_pdd['2023'] / 1000\n",
    "dfPred_xgb['2023_target'] = dfPred_xgb['2023_target'] / 1000\n",
    "dfPred_xgb['2023'] = dfPred_xgb['2023'] / 1000\n",
    "dfPred_xgb.sort_values(by='stakes_full', inplace=True)\n",
    "\n",
    "alpha = 0.8\n",
    "fontsize_title = 22\n",
    "f, (ax1, ax2) = plt.subplots(2,\n",
    "                             1,\n",
    "                             figsize=(8, 8),\n",
    "                             gridspec_kw={\"height_ratios\": [1, 0.5]})\n",
    "\n",
    "# Diff MAE:\n",
    "# ax1 = plt.subplot(M, N, pos)\n",
    "g = sns.barplot(\n",
    "    dfDiffMetrics_2023,\n",
    "    x='stakes_full',\n",
    "    y=f'diff_mae_2023',\n",
    "    ax=ax1,\n",
    "    dodge=False,\n",
    "    # color=color_diff_xgbplus,\n",
    "    hue='is_extrm_2023',\n",
    "    palette=palette_extremes,\n",
    "    alpha=alpha,\n",
    ")\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=90)\n",
    "\n",
    "# Target 2023:\n",
    "sns.scatterplot(dfPred_xgb,\n",
    "                x='stakes_full',\n",
    "                y=f'2023_target',\n",
    "                ax=ax2,\n",
    "                color=color_diff_xgbplus,\n",
    "                alpha=alpha,\n",
    "                s=200,\n",
    "                marker='x')\n",
    "sns.scatterplot(dfPred_pdd,\n",
    "                x='stakes_full',\n",
    "                y=f'2023',\n",
    "                ax=ax2,\n",
    "                alpha=alpha,\n",
    "                marker=marker_tim,\n",
    "                color=color_tim)\n",
    "g = sns.scatterplot(dfPred_xgb,\n",
    "                    x='stakes_full',\n",
    "                    y='2023',\n",
    "                    ax=ax2,\n",
    "                    alpha=alpha,\n",
    "                    color=color_xgbplus,\n",
    "                    marker=marker_xgb,\n",
    "                    s=200)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation=90)\n",
    "ax2.set_title(f'', fontsize=fontsize_title)\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.legend([], [], frameon=False)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=18)\n",
    "    ax.set_title(f'')\n",
    "\n",
    "ax1.set_ylabel('[m w.e. $a^{-1}$]', fontsize=18)\n",
    "ax2.set_ylabel('[m w.e. $a^{-1}$]')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tested on 2022:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_var = [['t2m', 'tp']]\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "M, N = 1, 2\n",
    "alpha = 0.8\n",
    "fontsize_title = 22\n",
    "\n",
    "for i, VARS in enumerate(possible_var):\n",
    "    vars_ = f'climate variables {VARS[0]} & {VARS[1]}'\n",
    "    dfMetrics_xgb = pd.read_csv(path_extreme +\n",
    "                                f'metrics_2022_{VARS[0]}_{VARS[1]}.csv')\n",
    "    dfPred_xgb = pd.read_csv(path_extreme +\n",
    "                             f'predictions_2022_{VARS[0]}_{VARS[1]}.csv')\n",
    "    dfPred_xgb.rename(columns={'2022': 2022}, inplace=True)\n",
    "\n",
    "    dfDiffMetrics_2022 = pd.merge(dfMetrics_xgb.drop(['Unnamed: 0'], axis=1),\n",
    "                                  dfMetrics_pdd_2022.drop(['Unnamed: 0'],\n",
    "                                                          axis=1),\n",
    "                                  on='stake',\n",
    "                                  suffixes=('_xgb', '_pdd'))\n",
    "    dfDiffMetrics_2022['diff_mae'] = dfDiffMetrics_2022[\n",
    "        'MAE_xgb'] - dfDiffMetrics_2022['MAE_pdd']\n",
    "\n",
    "    dfDiffMetrics_2022['stakes_full'] = dfDiffMetrics_2022.stake.apply(\n",
    "        lambda x: GL_SHORT[x.split('-')[0]]\n",
    "    ) + '-' + dfDiffMetrics_2022.stake.apply(lambda x: x.split('-')[1])\n",
    "    dfDiffMetrics_2022.sort_values(by='stakes_full', inplace=True)\n",
    "\n",
    "    # Diff MAE both:\n",
    "    ax1 = plt.subplot(M, N, i + 1)\n",
    "    g = sns.barplot(\n",
    "        dfDiffMetrics_2022,\n",
    "        x='stakes_full',\n",
    "        y=f'diff_mae',\n",
    "        ax=ax1,\n",
    "        dodge=False,\n",
    "        color=color_diff_xgbplus,\n",
    "        alpha=alpha,\n",
    "    )\n",
    "    h, l = g.get_legend_handles_labels()\n",
    "    ax1.set_xticklabels(ax1.get_xticklabels(), rotation=90)\n",
    "    ax1.set_ylabel('[m w.e. a$^{-1}$]', fontsize=18)\n",
    "    ax1.set_title(f'2022', fontsize=fontsize_title)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "372.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
